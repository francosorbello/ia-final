---
title: "VGR 2"
output: html_notebook
---

Paso 1: importar informacion y librer√≠as
```{r}
library("recommenderlab")
library(dplyr)
library("ggplot2")
library(readr)
ratings <- read.csv("scrappers/ratings.csv")
what <- load("/home/rulo/Documentos/UNCU-LINUX/ia/final/Building a Recommendation System with R_CodeFile/Chapter 5/prepared.RData")
dist_category <- table_items[, 1 - as.matrix(dist(category == "product"))]
dist_category2 <- table_items[, as.matrix(dist(category == "product"))]
class(table_items)
evaluateModel(ratings_matrix,table_items)
```

Paso 2: convierto a RealRatingMatrix para poder trabajar con recommenderlab
```{r}
ratings_realMatrix <- ratings %>% as("realRatingMatrix")
#normalizo
#ratings_realMatrix %>% normalize %>% getRatings %>% hist(main = "Rating normalizados por usuario")
#elimino users con menos de 10 reviews
ratings10 <-ratings_realMatrix[rowCounts(ratings_realMatrix) >= 10]
ratings10
```
Separacion de datos en test y training sets
```{r}
train_perc <- 0.8 #porcentaje de los datos que se usan en training
item_quant <- 8 #nro de reviews(item) por user. El valor es seleccionado buscando uno menor que el minimo de reviews para cualquier user(que es 10)
rating_treshold <- 3 #separa ratings entre valores "buenos" y "malos". Recordar que en el dataset los users rankean entre 1(min) y 5(max)
n_fold <- 5 #nro de veces que evaluo el dataset

#obtengo los sets de training y test usando la funcion evaluationScheme del packete recommenderlab
#se utiliza el metodo k-fold
eval_sets <- evaluationScheme(data = ratings10,
                              method = "cross-validation",
                              k = n_fold,
                              given = item_quant,
                              goodRating = rating_treshold
                              )
# eval_sets <- evaluationScheme(data = ratings10,
#                  method = "split",
#                  train = 0.8,
#                  given = -5,
#                  goodRating = rating_treshold,
#                  k = 1
# )
# getData(eval_sets,"known")
```

```{r}

#lista de distintas configs de modelos
#pruebo el sistema varias veces para encontrar el mejor algoritmo
models <- list(
  IBCF_cos = list(name = "IBCF", param = list(method ="cosine")),
  IBCF_cor = list(name = "IBCF", param = list(method ="pearson")),
  UBCF_cos = list(name = "UBCF", param = list(method ="cosine")),
  UBCF_cor = list(name = "UBCF", param = list(method ="pearson")),
  random = list(name = "RANDOM", param=NULL)
)

algorithms <- list(
  "random items" = list(name="RANDOM", param=NULL),
  "popular items" = list(name="POPULAR", param=NULL),
  "user-based CF" = list(name="UBCF", param=list(nn=50)),
  "item-based CF" = list(name="IBCF", param=list(k=50)),
  "SVD approximation" = list(name="SVD", param=list(k = 50))
)


# lista de nro de items a recomendar
# pruebo varios para verificar efectividad algoritmo
number_of_recs <- c(1,seq(2, 10, 2))
number_of_recs
#112

results <- evaluate(
  x = eval_sets,
  method = models,
  n = number_of_recs
)
#CURVA ROC
plot(results, annotate = 1, legend = "topleft")

```

Evaluacion y prediccion
```{r}
set_separator <- sample(x = c(TRUE,FALSE),size = nrow(ratings10),replace = TRUE,prob = c(0.8,0.2))

tset <- ratings10[set_separator,]
tset
kset <- ratings10[!set_separator,]
kset
tset = getData(eval_sets,"train")
tset
kset = getData(eval_sets,"known")

#getModel(rec)
pre2 <- predict(object = rec,newdata = kset,n=5)

#For byUser=TRUE, a matrix with a row for each user is returned
acurracy_mat <- calcPredictionAccuracy(
  x = pre,
  data = getData(eval_sets,"unknown"),
  byUser = TRUE
)
acurracy_mat
```

